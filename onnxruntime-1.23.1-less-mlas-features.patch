diff -Nuarp onnxruntime-1.23.1.orig/cmake/onnxruntime_mlas.cmake onnxruntime-1.23.1/cmake/onnxruntime_mlas.cmake
--- onnxruntime-1.23.1.orig/cmake/onnxruntime_mlas.cmake	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/cmake/onnxruntime_mlas.cmake	2025-10-20 19:18:18.278639722 +0800
@@ -440,7 +440,7 @@ else()
         set_source_files_properties(${MLAS_SRC_DIR}/sqnbitgemm_kernel_neon_int8_i8mm.cpp 
 				    PROPERTIES COMPILE_FLAGS " -march=armv8.2-a+i8mm ")
 
-        if (NOT APPLE)
+        if (FALSE)
           set(mlas_platform_srcs
             ${mlas_platform_srcs}
             ${MLAS_SRC_DIR}/aarch64/HalfGemmKernelNeon.S
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/mlas/inc/mlas.h onnxruntime-1.23.1/onnxruntime/core/mlas/inc/mlas.h
--- onnxruntime-1.23.1.orig/onnxruntime/core/mlas/inc/mlas.h	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/mlas/inc/mlas.h	2025-10-20 19:17:42.394580578 +0800
@@ -81,7 +81,7 @@ Abstract:
 //
 
 #if defined(MLAS_TARGET_AMD64) || defined (MLAS_TARGET_POWER)
-#define MLAS_SUPPORTS_GEMM_DOUBLE
+// #define MLAS_SUPPORTS_GEMM_DOUBLE
 #endif
 
 #if (!defined(_MSC_VER)) || (_MSC_VER >= 1930)
@@ -92,7 +92,7 @@ Abstract:
 // When building an universial binary for APPLE, this flag would
 // cause trouble for x64 target.
 
-#define MLAS_F16VEC_INTRINSICS_SUPPORTED
+// #define MLAS_F16VEC_INTRINSICS_SUPPORTED
 
 #endif //
 #endif // ARM64
@@ -1865,7 +1865,7 @@ MlasHalfGemmConvertPackB(
     void* PackedB
     );
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
 /**
  * @brief Whether current CPU supports Bfloat16(bf16) acceleration.
  */
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/mlasi.h onnxruntime-1.23.1/onnxruntime/core/mlas/lib/mlasi.h
--- onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/mlasi.h	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/mlas/lib/mlasi.h	2025-10-20 19:17:42.394738183 +0800
@@ -396,7 +396,7 @@ size_t
 
 #else
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
 typedef size_t(MLASCALL MLAS_SBGEMM_FLOAT_KERNEL)(
     const float* A,
     const bfloat16_t* B,
@@ -946,7 +946,7 @@ extern "C" {
 #else
     MLAS_GEMM_FLOAT_KERNEL MlasSgemmKernelZero;
     MLAS_GEMM_FLOAT_KERNEL MlasSgemmKernelAdd;
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
     MLAS_SBGEMM_FLOAT_KERNEL MlasSbgemmKernelZero;
     MLAS_SBGEMM_FLOAT_KERNEL MlasSbgemmKernelAdd;
 #endif
@@ -1099,7 +1099,7 @@ extern "C" {
 #define MLAS_QGEMM_THREAD_COMPLEXITY                65536
 #define MLAS_HGEMM_THREAD_COMPLEXITY                65536
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
 #define MLAS_SBGEMM_THREAD_COMPLEXITY (size_t(64) * size_t(1024))
 #endif
 
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/platform.cpp onnxruntime-1.23.1/onnxruntime/core/mlas/lib/platform.cpp
--- onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/platform.cpp	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/mlas/lib/platform.cpp	2025-10-20 19:20:25.591114687 +0800
@@ -598,7 +598,7 @@ Return Value:
 
     const bool HasI8MMInstructions = MLAS_CPUIDINFO::GetCPUIDInfo().HasArmNeon_I8MM();
     if (HasI8MMInstructions) {
-#if defined(__linux__)
+#if 0//defined(__linux__)
 
         this->GemmU8U8Dispatch = &MlasGemmU8X8DispatchUmmla;
         this->GemmU8S8Dispatch = &MlasGemmU8X8DispatchUmmla;
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/sbgemm.h onnxruntime-1.23.1/onnxruntime/core/mlas/lib/sbgemm.h
--- onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/sbgemm.h	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/mlas/lib/sbgemm.h	2025-10-20 19:17:42.394993009 +0800
@@ -30,7 +30,7 @@ Abstract:
         MLAS_SBGEMM_STRIDES Strides{128, 128, 256};
 --*/
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
 
 #pragma once
 
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/sbgemm_kernel_neon.cpp onnxruntime-1.23.1/onnxruntime/core/mlas/lib/sbgemm_kernel_neon.cpp
--- onnxruntime-1.23.1.orig/onnxruntime/core/mlas/lib/sbgemm_kernel_neon.cpp	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/mlas/lib/sbgemm_kernel_neon.cpp	2025-10-20 19:17:42.395084090 +0800
@@ -15,7 +15,7 @@ Abstract:
 
 --*/
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
 
 #include "arm_neon.h"
 #include "mlasi.h"
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/providers/cpu/math/matmul.cc onnxruntime-1.23.1/onnxruntime/core/providers/cpu/math/matmul.cc
--- onnxruntime-1.23.1.orig/onnxruntime/core/providers/cpu/math/matmul.cc	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/providers/cpu/math/matmul.cc	2025-10-20 19:17:42.395142238 +0800
@@ -133,7 +133,7 @@ Status MatMul<T>::Compute(OpKernelContex
 
   return Status::OK();
 }
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
 bool GemmPackBBfloat16(AllocatorPtr& alloc,
                        const Tensor& tensor_b,
                        bool trans_b,
@@ -180,7 +180,7 @@ Status MatMul<float>::PrePack(const Tens
   // only pack Matrix B
   if (input_idx == 1) {
     size_t packed_b_size;
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
     size_t dim1 = 0;
     size_t dim2 = 0;
     TensorShape b_shape = tensor.Shape();
@@ -258,7 +258,7 @@ Status MatMul<float>::Compute(OpKernelCo
   const size_t K = static_cast<size_t>(helper.K());
   const size_t lda = helper.Lda(trans_a);
   const size_t ldb = helper.Ldb(trans_b);
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
   if (use_fastmath_mode_ && !trans_b && ((N * K) >= kFastMathModeKernelsizeThreshold)) {
     std::vector<MLAS_SBGEMM_DATA_PARAMS> data(max_len);
     for (size_t i = 0; i < max_len; i++) {
diff -Nuarp onnxruntime-1.23.1.orig/onnxruntime/core/providers/cpu/math/matmul.h onnxruntime-1.23.1/onnxruntime/core/providers/cpu/math/matmul.h
--- onnxruntime-1.23.1.orig/onnxruntime/core/providers/cpu/math/matmul.h	2025-09-27 11:28:08.000000000 +0800
+++ onnxruntime-1.23.1/onnxruntime/core/providers/cpu/math/matmul.h	2025-10-20 19:17:42.395197251 +0800
@@ -30,7 +30,7 @@ class MatMul<float> final : public OpKer
     trans_batch_a_ = trans_batch_a_attr != 0;
     trans_batch_b_ = trans_batch_b_attr != 0;
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
     auto config_ops = info.GetConfigOptions().GetConfigEntry(kOrtSessionOptionsMlasGemmFastMathArm64Bfloat16);
     use_fastmath_mode_ = (config_ops == "1") && MlasBf16AccelerationSupported();
 #endif
@@ -56,7 +56,7 @@ class MatMul<float> final : public OpKer
   bool trans_batch_a_;
   bool trans_batch_b_;
 
-#if defined(__aarch64__) && defined(__linux__)
+#if 0//defined(__aarch64__) && defined(__linux__)
   // fastmath mode state
   bool use_fastmath_mode_;
   // sbgemm kernel is implemented as 8x8 blocks with weights pre-packed to 4 blocks of 4x2
